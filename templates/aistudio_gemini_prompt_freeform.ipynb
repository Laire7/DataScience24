{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE8UqxrDIez"
      },
      "source": [
        "### Install & import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWIuwKG2_oWE"
      },
      "outputs": [],
      "source": [
        "# Install the client library and import necessary modules.\n",
        "import google.generativeai as genai\n",
        "\n",
        "import base64\n",
        "import copy\n",
        "import hashlib\n",
        "import io\n",
        "import json\n",
        "import mimetypes\n",
        "import pathlib\n",
        "import pprint\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fet3lFjdKHEM"
      },
      "source": [
        "## Set the API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRWILAtCzBE"
      },
      "source": [
        "Add your API_KEY to the secrets manager in the left panel \"🔑\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LaLCwNlkCyQd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "# Configure the client library by providing your API key.\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weo-o73WDpdm"
      },
      "source": [
        "## Parse the arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uIog-0SyDuIF"
      },
      "outputs": [],
      "source": [
        "model = 'gemini-1.5-flash' # @param {isTemplate: true}\n",
        "contents_b64 = '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' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo2NCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RkbnEEIFEHFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d544fb7b-abac-40ff-92e0-cc9ae2d4bfd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'parts': [{'text': 'input: '},\n",
              "   {'file_data': {'mime_type': 'application/octet-stream',\n",
              "     'drive_id': '1FPXwEOcsCHMDSOKC0xwOjvKHcwe7GXNo'}},\n",
              "   {'text': 'output: 메뉴명: 라면\\\\n\\\\n1. 재료\\\\n라면 1봉지\\\\n스프 1/2개\\\\n대파 1뿌리\\\\n올리브유 2스푼\\\\n\\\\n* 조리순서\\\\n1. 평소대로 물을 550ml 넣고 끓여주세요 \\xa0 \\xa0\\\\n2. 끓는 물에 라면과 스프를 넣어주세요 여기서 포인트는 라면을 70~80%만 익혀주시는 거에요,이따가 라면 볶으면서 또 익혀 줄거기 때문에 푹 익히면 퍼질 수가 있어요~!포인트는 라면을 70~80%만 익히기\\\\n3. 살짝 덜 익은 라면 물을 버려주세요. 그 때 라면 국물 3~4스푼은 남겨주시고 버려주세요^^ \\xa0 \\xa0\\\\n4. 이제 팬에 올리브유 or 식용유 2스푼을 올려주세요 \\\\n5. 다음 아까 설익은 라면을 넣고 볶아줄거에요. 그리고 아까 라면 끓는 물 3~4스푼 기억나시죠?^^\\\\n6. 끓인 물 4스푼을 함께 넣어서 약 불에서 볶아주세요~ \\xa0\\\\n7. 다음 대파를 올려주시구요~~\\\\n8. 대파향이 솔솔~~ 날때까지 볶아주세요저는 백종원 레시피중에 가장 마음에 드는게 대파향인거 같아요 ㅎㅎ원래 파를 좋아하기도 하지만 대파향 솔솔 나는게 참 좋아요 \\\\n9. 다음 라면스프 1/2을 넣고 샤샤샥~ 볶아주세요\\\\n10. 조금 더 넣으면 혹시 짤수가 있으니 드셔보시면서 조절하는걸로~^^ \\xa0 \\xa0짠~! 완성되었어요,'},\n",
              "   {'text': 'input: '},\n",
              "   {'file_data': {'mime_type': 'application/octet-stream',\n",
              "     'drive_id': '1HAeGxLj-BIDcEQayzyrU3QpmtGYNRyKK'}},\n",
              "   {'text': 'output: '}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "gais_contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ca3e641ee9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242b7417-20d0-4884-f39b-3c522f015254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'temperature': 1, 'top_p': 0.95, 'top_k': 64, 'max_output_tokens': 8192}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "11ce12f5bbac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1b0c0a-48dc-488b-cac5-c83a309ddad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "safety_settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yoL3p3KPylFW"
      },
      "outputs": [],
      "source": [
        "# @title `show_file` function\n",
        "drive = None\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        if drive_id is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"📁 Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o9D5UdhL8MTk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "bfc0bf57-2d8f-43f1-a890-be0380630c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'drive' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4e14c6b849ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfile_data\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mshow_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e4153f678a02>\u001b[0m in \u001b[0;36mshow_file\u001b[0;34m(file_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdrive_id\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfile_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdrive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/gdrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'drive' referenced before assignment"
          ]
        }
      ],
      "source": [
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F6SKiuo88LQ"
      },
      "source": [
        "## Convert & upload files\n",
        "\n",
        "For each file, Google AI Studio either sent:\n",
        "- a Google Drive IDs\n",
        "- a URL, or\n",
        "- the raw bytes (`inline_data`).\n",
        "\n",
        "The API itself onlty understands two ways of sending files:\n",
        "\n",
        "- `inline_data` - where the bytes are placed inline in the request.\n",
        "- `file_data` - where the file is uploaded to the Files API, and you pass a reference to that file.\n",
        "\n",
        "This section goes through the `contents` from Google AI Studio, and uploads the file data, to the Files API, so Gemini can access it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_wJAs_ZfuwCq"
      },
      "outputs": [],
      "source": [
        "# @title `upload_file` function\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        hash = hashlib.sha256(data).hexdigest()\n",
        "        path = tempfiles / hash\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"📁 Files\"in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TehY-utE3OR"
      },
      "outputs": [],
      "source": [
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUFIM-r39cuc"
      },
      "source": [
        "Here is the coverted `Content`s:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ-sPFRSxdQg"
      },
      "outputs": [],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB2LxPmAB95V"
      },
      "outputs": [],
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm3RXwYuGtZK"
      },
      "outputs": [],
      "source": [
        "if generation_config.get(\"candidate_count\", 1) == 1:\n",
        "    display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjT4jtJc2aAk"
      },
      "outputs": [],
      "source": [
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ1YBkS4MV8L"
      },
      "source": [
        "## Or Create a chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOd-4IHUqx4R"
      },
      "outputs": [],
      "source": [
        "gemini = genai.GenerativeModel(\n",
        "    model_name=model,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOPCBs2grsIt"
      },
      "source": [
        "A `ChatSession`, should always end with the model's turn.\n",
        "\n",
        "So before creating the `chat` check whos turn was last.\n",
        "\n",
        "If the user was last, attach all but the last content as the `history` and send the last content with `send_message` to get the model's response.\n",
        "\n",
        "If the model was last, put the whole contents list in the history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIbdDOeFqyiE"
      },
      "outputs": [],
      "source": [
        "model_turn = contents[-1].get(\"role\", None) == \"user\"\n",
        "\n",
        "if model_turn:\n",
        "    chat = gemini.start_chat(history=contents[:-1])\n",
        "\n",
        "    response = chat.send_message(contents[-1])\n",
        "\n",
        "    if generation_config.get(\"candidate_count\", 1) == 1:\n",
        "        display(Markdown(response.text))\n",
        "else:\n",
        "    chat = gemini.start_chat(history=contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gWBb5UtOL5M"
      },
      "outputs": [],
      "source": [
        "if model_turn:\n",
        "    response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdz66HVvsnRc"
      },
      "source": [
        "After that use `send_message` to continue the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb87HPvBrx29"
      },
      "outputs": [],
      "source": [
        "# response = chat.send_message(\"Interesting, tell me more.\")\n",
        "# display(Markdown(response.text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}