{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE8UqxrDIez"
      },
      "source": [
        "### Install & import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWIuwKG2_oWE"
      },
      "outputs": [],
      "source": [
        "# Install the client library and import necessary modules.\n",
        "import google.generativeai as genai\n",
        "\n",
        "import base64\n",
        "import copy\n",
        "import hashlib\n",
        "import io\n",
        "import json\n",
        "import mimetypes\n",
        "import pathlib\n",
        "import pprint\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fet3lFjdKHEM"
      },
      "source": [
        "## Set the API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRWILAtCzBE"
      },
      "source": [
        "Add your API_KEY to the secrets manager in the left panel \"ğŸ”‘\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LaLCwNlkCyQd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "# Configure the client library by providing your API key.\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weo-o73WDpdm"
      },
      "source": [
        "## Parse the arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uIog-0SyDuIF"
      },
      "outputs": [],
      "source": [
        "model = 'gemini-1.5-flash' # @param {isTemplate: true}\n",
        "contents_b64 = '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' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo2NCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RkbnEEIFEHFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d544fb7b-abac-40ff-92e0-cc9ae2d4bfd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'parts': [{'text': 'input: '},\n",
              "   {'file_data': {'mime_type': 'application/octet-stream',\n",
              "     'drive_id': '1FPXwEOcsCHMDSOKC0xwOjvKHcwe7GXNo'}},\n",
              "   {'text': 'output: ë©”ë‰´ëª…: ë¼ë©´\\\\n\\\\n1. ì¬ë£Œ\\\\në¼ë©´ 1ë´‰ì§€\\\\nìŠ¤í”„ 1/2ê°œ\\\\nëŒ€íŒŒ 1ë¿Œë¦¬\\\\nì˜¬ë¦¬ë¸Œìœ  2ìŠ¤í‘¼\\\\n\\\\n* ì¡°ë¦¬ìˆœì„œ\\\\n1. í‰ì†ŒëŒ€ë¡œ ë¬¼ì„ 550ml ë„£ê³  ë“ì—¬ì£¼ì„¸ìš” \\xa0 \\xa0\\\\n2. ë“ëŠ” ë¬¼ì— ë¼ë©´ê³¼ ìŠ¤í”„ë¥¼ ë„£ì–´ì£¼ì„¸ìš” ì—¬ê¸°ì„œ í¬ì¸íŠ¸ëŠ” ë¼ë©´ì„ 70~80%ë§Œ ìµí˜€ì£¼ì‹œëŠ” ê±°ì—ìš”,ì´ë”°ê°€ ë¼ë©´ ë³¶ìœ¼ë©´ì„œ ë˜ ìµí˜€ ì¤„ê±°ê¸° ë•Œë¬¸ì— í‘¹ ìµíˆë©´ í¼ì§ˆ ìˆ˜ê°€ ìˆì–´ìš”~!í¬ì¸íŠ¸ëŠ” ë¼ë©´ì„ 70~80%ë§Œ ìµíˆê¸°\\\\n3. ì‚´ì§ ëœ ìµì€ ë¼ë©´ ë¬¼ì„ ë²„ë ¤ì£¼ì„¸ìš”. ê·¸ ë•Œ ë¼ë©´ êµ­ë¬¼ 3~4ìŠ¤í‘¼ì€ ë‚¨ê²¨ì£¼ì‹œê³  ë²„ë ¤ì£¼ì„¸ìš”^^ \\xa0 \\xa0\\\\n4. ì´ì œ íŒ¬ì— ì˜¬ë¦¬ë¸Œìœ  or ì‹ìš©ìœ  2ìŠ¤í‘¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš” \\\\n5. ë‹¤ìŒ ì•„ê¹Œ ì„¤ìµì€ ë¼ë©´ì„ ë„£ê³  ë³¶ì•„ì¤„ê±°ì—ìš”. ê·¸ë¦¬ê³  ì•„ê¹Œ ë¼ë©´ ë“ëŠ” ë¬¼ 3~4ìŠ¤í‘¼ ê¸°ì–µë‚˜ì‹œì£ ?^^\\\\n6. ë“ì¸ ë¬¼ 4ìŠ¤í‘¼ì„ í•¨ê»˜ ë„£ì–´ì„œ ì•½ ë¶ˆì—ì„œ ë³¶ì•„ì£¼ì„¸ìš”~ \\xa0\\\\n7. ë‹¤ìŒ ëŒ€íŒŒë¥¼ ì˜¬ë ¤ì£¼ì‹œêµ¬ìš”~~\\\\n8. ëŒ€íŒŒí–¥ì´ ì†”ì†”~~ ë‚ ë•Œê¹Œì§€ ë³¶ì•„ì£¼ì„¸ìš”ì €ëŠ” ë°±ì¢…ì› ë ˆì‹œí”¼ì¤‘ì— ê°€ì¥ ë§ˆìŒì— ë“œëŠ”ê²Œ ëŒ€íŒŒí–¥ì¸ê±° ê°™ì•„ìš” ã…ã…ì›ë˜ íŒŒë¥¼ ì¢‹ì•„í•˜ê¸°ë„ í•˜ì§€ë§Œ ëŒ€íŒŒí–¥ ì†”ì†” ë‚˜ëŠ”ê²Œ ì°¸ ì¢‹ì•„ìš” \\\\n9. ë‹¤ìŒ ë¼ë©´ìŠ¤í”„ 1/2ì„ ë„£ê³  ìƒ¤ìƒ¤ìƒ¥~ ë³¶ì•„ì£¼ì„¸ìš”\\\\n10. ì¡°ê¸ˆ ë” ë„£ìœ¼ë©´ í˜¹ì‹œ ì§¤ìˆ˜ê°€ ìˆìœ¼ë‹ˆ ë“œì…”ë³´ì‹œë©´ì„œ ì¡°ì ˆí•˜ëŠ”ê±¸ë¡œ~^^ \\xa0 \\xa0ì§ ~! ì™„ì„±ë˜ì—ˆì–´ìš”,'},\n",
              "   {'text': 'input: '},\n",
              "   {'file_data': {'mime_type': 'application/octet-stream',\n",
              "     'drive_id': '1HAeGxLj-BIDcEQayzyrU3QpmtGYNRyKK'}},\n",
              "   {'text': 'output: '}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "gais_contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ca3e641ee9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242b7417-20d0-4884-f39b-3c522f015254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'temperature': 1, 'top_p': 0.95, 'top_k': 64, 'max_output_tokens': 8192}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "11ce12f5bbac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1b0c0a-48dc-488b-cac5-c83a309ddad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "safety_settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yoL3p3KPylFW"
      },
      "outputs": [],
      "source": [
        "# @title `show_file` function\n",
        "drive = None\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        if drive_id is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"ğŸ“ Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o9D5UdhL8MTk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "bfc0bf57-2d8f-43f1-a890-be0380630c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'drive' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4e14c6b849ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfile_data\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mshow_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e4153f678a02>\u001b[0m in \u001b[0;36mshow_file\u001b[0;34m(file_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdrive_id\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mfile_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdrive\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/gdrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'drive' referenced before assignment"
          ]
        }
      ],
      "source": [
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F6SKiuo88LQ"
      },
      "source": [
        "## Convert & upload files\n",
        "\n",
        "For each file, Google AI Studio either sent:\n",
        "- a Google Drive IDs\n",
        "- a URL, or\n",
        "- the raw bytes (`inline_data`).\n",
        "\n",
        "The API itself onlty understands two ways of sending files:\n",
        "\n",
        "- `inline_data` - where the bytes are placed inline in the request.\n",
        "- `file_data` - where the file is uploaded to the Files API, and you pass a reference to that file.\n",
        "\n",
        "This section goes through the `contents` from Google AI Studio, and uploads the file data, to the Files API, so Gemini can access it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_wJAs_ZfuwCq"
      },
      "outputs": [],
      "source": [
        "# @title `upload_file` function\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        hash = hashlib.sha256(data).hexdigest()\n",
        "        path = tempfiles / hash\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"ğŸ“ Files\"in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TehY-utE3OR"
      },
      "outputs": [],
      "source": [
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUFIM-r39cuc"
      },
      "source": [
        "Here is the coverted `Content`s:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ-sPFRSxdQg"
      },
      "outputs": [],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB2LxPmAB95V"
      },
      "outputs": [],
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm3RXwYuGtZK"
      },
      "outputs": [],
      "source": [
        "if generation_config.get(\"candidate_count\", 1) == 1:\n",
        "    display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjT4jtJc2aAk"
      },
      "outputs": [],
      "source": [
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ1YBkS4MV8L"
      },
      "source": [
        "## Or Create a chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOd-4IHUqx4R"
      },
      "outputs": [],
      "source": [
        "gemini = genai.GenerativeModel(\n",
        "    model_name=model,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOPCBs2grsIt"
      },
      "source": [
        "A `ChatSession`, should always end with the model's turn.\n",
        "\n",
        "So before creating the `chat` check whos turn was last.\n",
        "\n",
        "If the user was last, attach all but the last content as the `history` and send the last content with `send_message` to get the model's response.\n",
        "\n",
        "If the model was last, put the whole contents list in the history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIbdDOeFqyiE"
      },
      "outputs": [],
      "source": [
        "model_turn = contents[-1].get(\"role\", None) == \"user\"\n",
        "\n",
        "if model_turn:\n",
        "    chat = gemini.start_chat(history=contents[:-1])\n",
        "\n",
        "    response = chat.send_message(contents[-1])\n",
        "\n",
        "    if generation_config.get(\"candidate_count\", 1) == 1:\n",
        "        display(Markdown(response.text))\n",
        "else:\n",
        "    chat = gemini.start_chat(history=contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gWBb5UtOL5M"
      },
      "outputs": [],
      "source": [
        "if model_turn:\n",
        "    response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdz66HVvsnRc"
      },
      "source": [
        "After that use `send_message` to continue the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb87HPvBrx29"
      },
      "outputs": [],
      "source": [
        "# response = chat.send_message(\"Interesting, tell me more.\")\n",
        "# display(Markdown(response.text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}